{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "\n",
    "It's often (but not always) useful to reduce words to their roots. One reason for doing this may be that word tense or conjugation is not important for your model. It would be useful to combine variations of a word together. Then for models like Naive Bayes where each word is a feature, we can strongly reduce our feature space.\n",
    "\n",
    "Let's see what this looks like. First, let's tokenize a bit of text from the wikipedia page on data science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize  # for tokenizing our text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a few tokens: [u'Data', u'science', u'From', u'Wikipedia', u',', u'the', u'free', u'encyclopedia', u'Data', u'Science']\n",
      "number of tokens: 1684\n",
      "number of unique tokens: 665\n"
     ]
    }
   ],
   "source": [
    "# sample text from wikipedia\n",
    "import codecs\n",
    "text = codecs.open('../data/nlp_data/sample.txt', \"r\", \"utf-8\").read()\n",
    "\n",
    "#tokenize the code\n",
    "word_bag = wordpunct_tokenize(text)\n",
    "print 'a few tokens:', word_bag[:10]\n",
    "print 'number of tokens:', len(word_bag)\n",
    "print 'number of unique tokens:', len(set(word_bag))\n",
    "#665 unique words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for common word endings to clip off. Start with the suffix, '-s', '-er', '-ing'. But be careful to only strip these tokens when they appear at the end of the word. Write rules into the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define a function to stem tokens based on rules.\n",
    "\n",
    "def stem(tokens):\n",
    "    '''rules-based stemming of a bunch of tokens\n",
    "    if end of word has s or er or ing then\n",
    "        substr\n",
    "    '''\n",
    "    \n",
    "    new_bag = []\n",
    "    for token in tokens:\n",
    "        # define rules here\n",
    "        if token:  # edit this to test for some condition involving `token`\n",
    "            # append the stemmed token to the bag.\n",
    "        elif token:\n",
    "            # append the stemmed token to the bag.\n",
    "            # keep adding more rules in elif statements.\n",
    "        else:  # base case there no stemming is required\n",
    "            new_bag.append(token)\n",
    "\n",
    "    return new_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check how well you're doing by running this cell:\n",
    "\n",
    "print 'initial number of unique tokens:', len(set(word_bag))\n",
    "print 'stemmed number of unique tokens:', len(set(stem(word_bag)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do we have to refine our rules? Are we stripping away too many letters? Run this cell to see\n",
    "\n",
    "for token in stem(word_bag):\n",
    "    print token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to add more rules and see how much you can pare down the feature set, i.e. the number of unique tokens. Try not to strip too much off the words!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porter Stemmer\n",
    "\n",
    "The classic stemmer is the Porter stemmer which is [available in NLTK](http://www.nltk.org/api/nltk.stem.html#module-nltk.stem.porter). Others are available, too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial number of unique tokens: 665\n",
      "stemmed number of unique tokens: 601\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to see how the Porter Stemmer performs.\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "print 'initial number of unique tokens:', len(set(word_bag))\n",
    "print 'stemmed number of unique tokens:', len({ps.stem(token) for token in word_bag})  # this uses a set comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\n",
      "scienc\n",
      "From\n",
      "Wikipedia\n",
      ",\n",
      "the\n",
      "free\n",
      "encyclopedia\n",
      "Data\n",
      "Scienc\n",
      "Venn\n",
      "Diagram\n",
      "Data\n",
      "scienc\n",
      "is\n",
      "the\n",
      "studi\n",
      "of\n",
      "the\n",
      "generaliz\n",
      "extract\n",
      "of\n",
      "knowledg\n",
      "from\n",
      "data\n",
      ",[\n",
      "1\n",
      "]\n",
      "yet\n",
      "the\n",
      "key\n",
      "word\n",
      "is\n",
      "scienc\n",
      ".[\n",
      "2\n",
      "]\n",
      "It\n",
      "incorpor\n",
      "vari\n",
      "element\n",
      "and\n",
      "build\n",
      "on\n",
      "techniqu\n",
      "and\n",
      "theori\n",
      "from\n",
      "mani\n",
      "field\n",
      ",\n",
      "includ\n",
      "signal\n",
      "process\n",
      ",\n",
      "mathemat\n",
      ",\n",
      "probabl\n",
      "model\n",
      ",\n",
      "machin\n",
      "learn\n",
      ",\n",
      "statist\n",
      "learn\n",
      ",\n",
      "comput\n",
      "program\n",
      ",\n",
      "data\n",
      "engin\n",
      ",\n",
      "pattern\n",
      "recognit\n",
      "and\n",
      "learn\n",
      ",\n",
      "visual\n",
      ",\n",
      "uncertainti\n",
      "model\n",
      ",\n",
      "data\n",
      "wareh\n",
      ",\n",
      "and\n",
      "high\n",
      "perform\n",
      "comput\n",
      "with\n",
      "the\n",
      "goal\n",
      "of\n",
      "extract\n",
      "mean\n",
      "from\n",
      "data\n",
      "and\n",
      "creat\n",
      "data\n",
      "product\n",
      ".\n",
      "The\n",
      "subject\n",
      "is\n",
      "not\n",
      "restrict\n",
      "to\n",
      "onli\n",
      "big\n",
      "data\n",
      ",\n",
      "although\n",
      "the\n",
      "fact\n",
      "that\n",
      "data\n",
      "is\n",
      "scale\n",
      "up\n",
      "make\n",
      "big\n",
      "data\n",
      "an\n",
      "import\n",
      "aspect\n",
      "of\n",
      "data\n",
      "scienc\n",
      ".\n",
      "A\n",
      "practition\n",
      "of\n",
      "data\n",
      "scienc\n",
      "is\n",
      "call\n",
      "a\n",
      "data\n",
      "scientist\n",
      ".\n",
      "Data\n",
      "scientist\n",
      "solv\n",
      "complex\n",
      "data\n",
      "problem\n",
      "through\n",
      "employ\n",
      "deep\n",
      "expertis\n",
      "in\n",
      "some\n",
      "scientif\n",
      "disciplin\n",
      ".\n",
      "It\n",
      "is\n",
      "gener\n",
      "expect\n",
      "that\n",
      "data\n",
      "scientist\n",
      "are\n",
      "abl\n",
      "to\n",
      "work\n",
      "with\n",
      "variou\n",
      "element\n",
      "of\n",
      "mathemat\n",
      ",\n",
      "statist\n",
      "and\n",
      "comput\n",
      "scienc\n",
      ",\n",
      "although\n",
      "expertis\n",
      "in\n",
      "these\n",
      "subject\n",
      "are\n",
      "not\n",
      "requir\n",
      ".[\n",
      "3\n",
      "]\n",
      "Howev\n",
      ",\n",
      "a\n",
      "data\n",
      "scientist\n",
      "is\n",
      "most\n",
      "like\n",
      "to\n",
      "be\n",
      "an\n",
      "expert\n",
      "in\n",
      "onli\n",
      "one\n",
      "or\n",
      "two\n",
      "of\n",
      "these\n",
      "disciplin\n",
      "and\n",
      "profici\n",
      "in\n",
      "anoth\n",
      "two\n",
      "or\n",
      "three\n",
      ".\n",
      "Therefor\n",
      "data\n",
      "scienc\n",
      "is\n",
      "practic\n",
      "as\n",
      "a\n",
      "team\n",
      ",\n",
      "where\n",
      "the\n",
      "membership\n",
      "of\n",
      "the\n",
      "team\n",
      "have\n",
      "a\n",
      "varieti\n",
      "of\n",
      "expertis\n",
      ".\n",
      "Data\n",
      "scientist\n",
      "use\n",
      "the\n",
      "abil\n",
      "to\n",
      "find\n",
      "and\n",
      "interpret\n",
      "rich\n",
      "data\n",
      "sourc\n",
      ",\n",
      "manag\n",
      "larg\n",
      "amount\n",
      "of\n",
      "data\n",
      "despit\n",
      "hardwar\n",
      ",\n",
      "softwar\n",
      "and\n",
      "bandwidth\n",
      "constraint\n",
      ",\n",
      "merg\n",
      "data\n",
      "sourc\n",
      "togeth\n",
      ",\n",
      "ensur\n",
      "consist\n",
      "of\n",
      "data\n",
      "-\n",
      "set\n",
      ",\n",
      "creat\n",
      "visual\n",
      "to\n",
      "aid\n",
      "in\n",
      "understand\n",
      "data\n",
      ",\n",
      "build\n",
      "mathemat\n",
      "model\n",
      "use\n",
      "the\n",
      "data\n",
      ",\n",
      "present\n",
      "and\n",
      "commun\n",
      "the\n",
      "data\n",
      "insight\n",
      "/\n",
      "find\n",
      "to\n",
      "specialist\n",
      "and\n",
      "scientist\n",
      "in\n",
      "their\n",
      "team\n",
      "and\n",
      "if\n",
      "requir\n",
      "to\n",
      "a\n",
      "non\n",
      "-\n",
      "expert\n",
      "audienc\n",
      ".\n",
      "Data\n",
      "scienc\n",
      "techniqu\n",
      "affect\n",
      "research\n",
      "in\n",
      "mani\n",
      "domain\n",
      ",\n",
      "includ\n",
      "the\n",
      "biolog\n",
      "scienc\n",
      ",\n",
      "medic\n",
      "informat\n",
      ",\n",
      "health\n",
      "care\n",
      ",\n",
      "social\n",
      "scienc\n",
      "and\n",
      "the\n",
      "human\n",
      ".\n",
      "It\n",
      "heavili\n",
      "influenc\n",
      "econom\n",
      ",\n",
      "busi\n",
      "and\n",
      "financ\n",
      ".\n",
      "From\n",
      "the\n",
      "busi\n",
      "perspect\n",
      ",\n",
      "data\n",
      "scienc\n",
      "is\n",
      "an\n",
      "integr\n",
      "part\n",
      "of\n",
      "competit\n",
      "intellig\n",
      ",\n",
      "a\n",
      "newli\n",
      "emerg\n",
      "field\n",
      "that\n",
      "encompass\n",
      "a\n",
      "number\n",
      "of\n",
      "activ\n",
      ",\n",
      "such\n",
      "as\n",
      "data\n",
      "mine\n",
      "and\n",
      "data\n",
      "analysi\n",
      ".[\n",
      "4\n",
      "]\n",
      "Content\n",
      "1\n",
      "Histori\n",
      "2\n",
      "Domain\n",
      "Specif\n",
      "Interest\n",
      "3\n",
      "Critic\n",
      "4\n",
      "Research\n",
      "Area\n",
      "4\n",
      ".\n",
      "1\n",
      "Secur\n",
      "Data\n",
      "Scienc\n",
      "4\n",
      ".\n",
      "2\n",
      "Clinic\n",
      "Data\n",
      "Scienc\n",
      "5\n",
      "Confer\n",
      "6\n",
      "Further\n",
      "read\n",
      "7\n",
      "Refer\n",
      "Histori\n",
      "The\n",
      "term\n",
      "\"\n",
      "data\n",
      "scienc\n",
      "\"\n",
      "(\n",
      "origin\n",
      "use\n",
      "interchang\n",
      "with\n",
      "\"\n",
      "datalog\n",
      "\")\n",
      "ha\n",
      "exist\n",
      "for\n",
      "over\n",
      "thirti\n",
      "year\n",
      "and\n",
      "wa\n",
      "use\n",
      "initi\n",
      "as\n",
      "a\n",
      "substitut\n",
      "for\n",
      "comput\n",
      "scienc\n",
      "by\n",
      "Peter\n",
      "Naur\n",
      "in\n",
      "1960\n",
      ".\n",
      "In\n",
      "1974\n",
      ",\n",
      "Naur\n",
      "publish\n",
      "Concis\n",
      "Survey\n",
      "of\n",
      "Comput\n",
      "Method\n",
      ",\n",
      "which\n",
      "freeli\n",
      "use\n",
      "the\n",
      "term\n",
      "data\n",
      "scienc\n",
      "in\n",
      "it\n",
      "survey\n",
      "of\n",
      "the\n",
      "contemporari\n",
      "data\n",
      "process\n",
      "method\n",
      "that\n",
      "are\n",
      "use\n",
      "in\n",
      "a\n",
      "wide\n",
      "rang\n",
      "of\n",
      "applic\n",
      ".\n",
      "In\n",
      "1996\n",
      ",\n",
      "member\n",
      "of\n",
      "the\n",
      "Intern\n",
      "Feder\n",
      "of\n",
      "Classif\n",
      "Societi\n",
      "(\n",
      "IFC\n",
      ")\n",
      "met\n",
      "in\n",
      "Tokyo\n",
      "for\n",
      "their\n",
      "biennial\n",
      "confer\n",
      ".\n",
      "Here\n",
      ",\n",
      "for\n",
      "the\n",
      "first\n",
      "time\n",
      ",\n",
      "the\n",
      "term\n",
      "data\n",
      "scienc\n",
      "is\n",
      "includ\n",
      "in\n",
      "the\n",
      "titl\n",
      "of\n",
      "the\n",
      "confer\n",
      "(\"\n",
      "Data\n",
      "Scienc\n",
      ",\n",
      "classif\n",
      ",\n",
      "and\n",
      "relat\n",
      "method\n",
      "\").\n",
      "On\n",
      "10\n",
      "Novemb\n",
      "1997\n",
      ",\n",
      "C\n",
      ".\n",
      "F\n",
      ".\n",
      "Jeff\n",
      "Wu\n",
      "gave\n",
      "hi\n",
      "inaugur\n",
      "lectur\n",
      "entitl\n",
      "\"\n",
      "Statist\n",
      "=\n",
      "Data\n",
      "Scienc\n",
      "?\"\n",
      "in\n",
      "honor\n",
      "of\n",
      "hi\n",
      "appoint\n",
      "to\n",
      "the\n",
      "H\n",
      ".\n",
      "C\n",
      ".\n",
      "Carver\n",
      "Collegi\n",
      "Professorship\n",
      "in\n",
      "Statist\n",
      "at\n",
      "the\n",
      "Univers\n",
      "of\n",
      "Michigan\n",
      ".[\n",
      "5\n",
      "]\n",
      "In\n",
      "thi\n",
      "lectur\n",
      ",\n",
      "he\n",
      "first\n",
      "focus\n",
      "on\n",
      "the\n",
      "ident\n",
      "of\n",
      "statist\n",
      "in\n",
      "scienc\n",
      ".\n",
      "He\n",
      "then\n",
      "character\n",
      "statist\n",
      "work\n",
      "as\n",
      "data\n",
      "collect\n",
      ",\n",
      "data\n",
      "model\n",
      "and\n",
      "analysi\n",
      ",\n",
      "and\n",
      "problem\n",
      "solv\n",
      "and\n",
      "decis\n",
      "make\n",
      ".\n",
      "In\n",
      "conclus\n",
      ",\n",
      "he\n",
      "propos\n",
      "that\n",
      "statist\n",
      "be\n",
      "renam\n",
      "data\n",
      "scienc\n",
      "and\n",
      "statistician\n",
      "data\n",
      "scientist\n",
      ".[\n",
      "5\n",
      "]\n",
      "Later\n",
      ",\n",
      "he\n",
      "present\n",
      "hi\n",
      "lectur\n",
      "entitl\n",
      "\"\n",
      "Statist\n",
      "=\n",
      "Data\n",
      "Scienc\n",
      "?\"\n",
      "as\n",
      "the\n",
      "first\n",
      "of\n",
      "hi\n",
      "1998\n",
      "P\n",
      ".\n",
      "C\n",
      ".\n",
      "Mahalanobi\n",
      "Memori\n",
      "Lectur\n",
      ".[\n",
      "6\n",
      "]\n",
      "These\n",
      "lectur\n",
      "honor\n",
      "Prasanta\n",
      "Chandra\n",
      "Mahalanobi\n",
      ",\n",
      "an\n",
      "Indian\n",
      "scientist\n",
      "and\n",
      "statistician\n",
      "and\n",
      "founder\n",
      "of\n",
      "the\n",
      "Indian\n",
      "Statist\n",
      "Institut\n",
      ".\n",
      "In\n",
      "2001\n",
      ",\n",
      "William\n",
      "S\n",
      ".\n",
      "Cleveland\n",
      "introduc\n",
      "the\n",
      "notion\n",
      "of\n",
      "data\n",
      "scienc\n",
      "as\n",
      "an\n",
      "independ\n",
      "disciplin\n",
      ",\n",
      "extend\n",
      "the\n",
      "field\n",
      "of\n",
      "statist\n",
      "to\n",
      "incorpor\n",
      "\"\n",
      "advanc\n",
      "in\n",
      "comput\n",
      "with\n",
      "data\n",
      "\"\n",
      "in\n",
      "hi\n",
      "articl\n",
      "\"\n",
      "Data\n",
      "Scienc\n",
      ":\n",
      "An\n",
      "Action\n",
      "Plan\n",
      "for\n",
      "Expand\n",
      "the\n",
      "Technic\n",
      "Area\n",
      "of\n",
      "the\n",
      "Field\n",
      "of\n",
      "Statist\n",
      ",\"\n",
      "which\n",
      "wa\n",
      "publish\n",
      "in\n",
      "Volum\n",
      "69\n",
      ",\n",
      "No\n",
      ".\n",
      "1\n",
      ",\n",
      "of\n",
      "the\n",
      "April\n",
      "2001\n",
      "edit\n",
      "of\n",
      "the\n",
      "Intern\n",
      "Statist\n",
      "Review\n",
      "/\n",
      "Revu\n",
      "International\n",
      "de\n",
      "Statistiqu\n",
      ".[\n",
      "7\n",
      "]\n",
      "In\n",
      "hi\n",
      "report\n",
      ",\n",
      "Cleveland\n",
      "establish\n",
      "six\n",
      "technic\n",
      "area\n",
      "which\n",
      "he\n",
      "believ\n",
      "to\n",
      "encompass\n",
      "the\n",
      "field\n",
      "of\n",
      "data\n",
      "scienc\n",
      ":\n",
      "multidisciplinari\n",
      "investig\n",
      ",\n",
      "model\n",
      "and\n",
      "method\n",
      "for\n",
      "data\n",
      ",\n",
      "comput\n",
      "with\n",
      "data\n",
      ",\n",
      "pedagogi\n",
      ",\n",
      "tool\n",
      "evalu\n",
      ",\n",
      "and\n",
      "theori\n",
      ".\n",
      "In\n",
      "April\n",
      "2002\n",
      ",\n",
      "the\n",
      "Intern\n",
      "Council\n",
      "for\n",
      "Scienc\n",
      ":\n",
      "Committe\n",
      "on\n",
      "Data\n",
      "for\n",
      "Scienc\n",
      "and\n",
      "Technolog\n",
      "(\n",
      "CODATA\n",
      ")[\n",
      "8\n",
      "]\n",
      "start\n",
      "the\n",
      "Data\n",
      "Scienc\n",
      "Journal\n",
      ",[\n",
      "9\n",
      "]\n",
      "a\n",
      "public\n",
      "focus\n",
      "on\n",
      "issu\n",
      "such\n",
      "as\n",
      "the\n",
      "descript\n",
      "of\n",
      "data\n",
      "system\n",
      ",\n",
      "their\n",
      "public\n",
      "on\n",
      "the\n",
      "internet\n",
      ",\n",
      "applic\n",
      "and\n",
      "legal\n",
      "issu\n",
      ".[\n",
      "10\n",
      "]\n",
      "Shortli\n",
      "thereaft\n",
      ",\n",
      "in\n",
      "Januari\n",
      "2003\n",
      ",\n",
      "Columbia\n",
      "Univers\n",
      "began\n",
      "publish\n",
      "The\n",
      "Journal\n",
      "of\n",
      "Data\n",
      "Scienc\n",
      ",[\n",
      "11\n",
      "]\n",
      "which\n",
      "provid\n",
      "a\n",
      "platform\n",
      "for\n",
      "all\n",
      "data\n",
      "worker\n",
      "to\n",
      "present\n",
      "their\n",
      "view\n",
      "and\n",
      "exchang\n",
      "idea\n",
      ".\n",
      "The\n",
      "journal\n",
      "wa\n",
      "larg\n",
      "devot\n",
      "to\n",
      "the\n",
      "applic\n",
      "of\n",
      "statist\n",
      "method\n",
      "and\n",
      "quantit\n",
      "research\n",
      ".\n",
      "In\n",
      "2005\n",
      ",\n",
      "The\n",
      "Nation\n",
      "Scienc\n",
      "Board\n",
      "publish\n",
      "\"\n",
      "Long\n",
      "-\n",
      "live\n",
      "Digit\n",
      "Data\n",
      "Collect\n",
      ":\n",
      "Enabl\n",
      "Research\n",
      "and\n",
      "Educ\n",
      "in\n",
      "the\n",
      "21st\n",
      "Centuri\n",
      "\"\n",
      "defin\n",
      "data\n",
      "scientist\n",
      "as\n",
      "\"\n",
      "the\n",
      "inform\n",
      "and\n",
      "comput\n",
      "scientist\n",
      ",\n",
      "databas\n",
      "and\n",
      "softwar\n",
      "and\n",
      "programm\n",
      ",\n",
      "disciplinari\n",
      "expert\n",
      ",\n",
      "curat\n",
      "and\n",
      "expert\n",
      "annot\n",
      ",\n",
      "librarian\n",
      ",\n",
      "archivist\n",
      ",\n",
      "and\n",
      "other\n",
      ",\n",
      "who\n",
      "are\n",
      "crucial\n",
      "to\n",
      "the\n",
      "success\n",
      "manag\n",
      "of\n",
      "a\n",
      "digit\n",
      "data\n",
      "collect\n",
      "\"\n",
      "whose\n",
      "primari\n",
      "activ\n",
      "is\n",
      "to\n",
      "\"\n",
      "conduct\n",
      "creativ\n",
      "inquiri\n",
      "and\n",
      "analysi\n",
      ".\"[\n",
      "12\n",
      "]\n",
      "In\n",
      "2008\n",
      ",\n",
      "DJ\n",
      "Patil\n",
      "and\n",
      "Jeff\n",
      "Hammerbach\n",
      "coin\n",
      "the\n",
      "term\n",
      "\"\n",
      "data\n",
      "scientist\n",
      "\"\n",
      "to\n",
      "defin\n",
      "their\n",
      "job\n",
      "at\n",
      "LinkedIn\n",
      "and\n",
      "Facebook\n",
      ",\n",
      "respect\n",
      ".\n",
      "In\n",
      "2012\n",
      ",\n",
      "the\n",
      "first\n",
      "Wikipedia\n",
      "articl\n",
      "on\n",
      "Data\n",
      "Scienc\n",
      "wa\n",
      "creat\n",
      ".\n",
      "Domain\n",
      "Specif\n",
      "Interest\n",
      "Data\n",
      "scienc\n",
      "is\n",
      "the\n",
      "practic\n",
      "of\n",
      "deriv\n",
      "valuabl\n",
      "insight\n",
      "from\n",
      "data\n",
      ".\n",
      "Data\n",
      "scienc\n",
      "is\n",
      "emerg\n",
      "to\n",
      "meet\n",
      "the\n",
      "challeng\n",
      "of\n",
      "process\n",
      "veri\n",
      "larg\n",
      "data\n",
      "set\n",
      "i\n",
      ".\n",
      "e\n",
      ".\n",
      "\"\n",
      "Big\n",
      "Data\n",
      "\"\n",
      "consist\n",
      "of\n",
      "structur\n",
      ",\n",
      "unstructur\n",
      "or\n",
      "semi\n",
      "-\n",
      "structur\n",
      "data\n",
      "that\n",
      "larg\n",
      "enterpris\n",
      "produc\n",
      ".\n",
      "A\n",
      "domain\n",
      "at\n",
      "center\n",
      "stage\n",
      "of\n",
      "data\n",
      "scienc\n",
      "is\n",
      "the\n",
      "explos\n",
      "of\n",
      "new\n",
      "data\n",
      "gener\n",
      "from\n",
      "smart\n",
      "devic\n",
      ",\n",
      "web\n",
      ",\n",
      "mobil\n",
      "and\n",
      "social\n",
      "media\n",
      ".\n",
      "Data\n",
      "scienc\n",
      "requir\n",
      "a\n",
      "versatil\n",
      "skill\n",
      "-\n",
      "set\n",
      ".\n",
      "Mani\n",
      "practic\n",
      "data\n",
      "scientist\n",
      "commonli\n",
      "special\n",
      "in\n",
      "specif\n",
      "domain\n",
      "such\n",
      "as\n",
      "the\n",
      "field\n",
      "of\n",
      "market\n",
      ",\n",
      "medic\n",
      ",\n",
      "secur\n",
      ",\n",
      "fraud\n",
      "and\n",
      "financ\n",
      ".\n",
      "Howev\n",
      ",\n",
      "data\n",
      "scientist\n",
      "reli\n",
      "heavili\n",
      "upon\n",
      "element\n",
      "of\n",
      "signal\n",
      "process\n",
      ",\n",
      "statist\n",
      ",\n",
      "machin\n",
      "learn\n",
      ",\n",
      "text\n",
      "retriev\n",
      "and\n",
      "natur\n",
      "languag\n",
      "process\n",
      "to\n",
      "analyz\n",
      "data\n",
      "and\n",
      "interpret\n",
      "result\n",
      ".\n",
      "Critic\n",
      "Although\n",
      "use\n",
      "of\n",
      "the\n",
      "term\n",
      "data\n",
      "scienc\n",
      "ha\n",
      "explod\n",
      "in\n",
      "busi\n",
      "environ\n",
      ",\n",
      "mani\n",
      "academ\n",
      "and\n",
      "journalist\n",
      "see\n",
      "no\n",
      "distinct\n",
      "between\n",
      "data\n",
      "scienc\n",
      "and\n",
      "statist\n",
      ".\n",
      "Write\n",
      "in\n",
      "Forb\n",
      ",\n",
      "Gil\n",
      "Press\n",
      "argu\n",
      "that\n",
      "data\n",
      "scienc\n",
      "is\n",
      "a\n",
      "buzzword\n",
      "without\n",
      "a\n",
      "clear\n",
      "definit\n",
      "and\n",
      "ha\n",
      "simpli\n",
      "replac\n",
      "“\n",
      "busi\n",
      "analyt\n",
      "”\n",
      "in\n",
      "context\n",
      "such\n",
      "as\n",
      "graduat\n",
      "degre\n",
      "program\n",
      ".[\n",
      "13\n",
      "]\n",
      "In\n",
      "the\n",
      "question\n",
      "-\n",
      "and\n",
      "-\n",
      "answer\n",
      "section\n",
      "of\n",
      "hi\n",
      "keynot\n",
      "address\n",
      "at\n",
      "the\n",
      "Joint\n",
      "Statist\n",
      "Meet\n",
      "of\n",
      "American\n",
      "Statist\n",
      "Associ\n",
      ",\n",
      "note\n",
      "appli\n",
      "statistician\n",
      "Nate\n",
      "Silver\n",
      "said\n",
      ",\n",
      "“\n",
      "I\n",
      "think\n",
      "data\n",
      "-\n",
      "scientist\n",
      "is\n",
      "a\n",
      "sex\n",
      "up\n",
      "term\n",
      "for\n",
      "a\n",
      "statistician\n",
      "....\n",
      "Statist\n",
      "is\n",
      "a\n",
      "branch\n",
      "of\n",
      "scienc\n",
      ".\n",
      "Data\n",
      "scientist\n",
      "is\n",
      "slightli\n",
      "redund\n",
      "in\n",
      "some\n",
      "way\n",
      "and\n",
      "peopl\n",
      "shouldn\n",
      "’\n",
      "t\n",
      "berat\n",
      "the\n",
      "term\n",
      "statistician\n",
      ".”[\n",
      "14\n",
      "]\n",
      "Research\n",
      "Area\n",
      "As\n",
      "an\n",
      "interdisciplinari\n",
      "subject\n",
      ",\n",
      "data\n",
      "scienc\n",
      "draw\n",
      "scientif\n",
      "inquiri\n",
      "from\n",
      "a\n",
      "broad\n",
      "rang\n",
      "of\n",
      "academ\n",
      "subject\n",
      "area\n",
      ",\n",
      "mostli\n",
      "relat\n",
      "to\n",
      "the\n",
      "hard\n",
      "scienc\n",
      ".\n",
      "Some\n",
      "area\n",
      "of\n",
      "research\n",
      "are\n",
      ":\n",
      "Cloud\n",
      "comput\n",
      "Databas\n",
      "and\n",
      "inform\n",
      "integr\n",
      "Signal\n",
      "Process\n",
      "Learn\n",
      ",\n",
      "natur\n",
      "languag\n",
      "process\n",
      "and\n",
      "inform\n",
      "extract\n",
      "Comput\n",
      "vision\n",
      "Inform\n",
      "retriev\n",
      "and\n",
      "web\n",
      "inform\n",
      "access\n",
      "Knowledg\n",
      "discoveri\n",
      "in\n",
      "social\n",
      "and\n",
      "inform\n",
      "network\n",
      "Secur\n",
      "Data\n",
      "Scienc\n",
      "Data\n",
      "scienc\n",
      "ha\n",
      "a\n",
      "long\n",
      "and\n",
      "rich\n",
      "histori\n",
      "in\n",
      "secur\n",
      "and\n",
      "fraud\n",
      "monitor\n",
      "refer\n",
      "need\n",
      ".\n",
      "Secur\n",
      "data\n",
      "scienc\n",
      "is\n",
      "focus\n",
      "on\n",
      "advanc\n",
      "inform\n",
      "secur\n",
      "through\n",
      "practic\n",
      "applic\n",
      "of\n",
      "exploratori\n",
      "data\n",
      "analysi\n",
      ",\n",
      "statist\n",
      ",\n",
      "machin\n",
      "learn\n",
      "and\n",
      "data\n",
      "visual\n",
      ".\n",
      "Although\n",
      "the\n",
      "tool\n",
      "and\n",
      "techniqu\n",
      "are\n",
      "no\n",
      "differ\n",
      "that\n",
      "those\n",
      "use\n",
      "in\n",
      "data\n",
      "scienc\n",
      "in\n",
      "ani\n",
      "data\n",
      "domain\n",
      ",\n",
      "thi\n",
      "group\n",
      "ha\n",
      "a\n",
      "micro\n",
      "-\n",
      "focu\n",
      "on\n",
      "reduc\n",
      "risk\n",
      ",\n",
      "identifi\n",
      "fraud\n",
      "or\n",
      "malici\n",
      "insid\n",
      "use\n",
      "data\n",
      "scienc\n",
      ".\n",
      "The\n",
      "inform\n",
      "secur\n",
      "and\n",
      "fraud\n",
      "prevent\n",
      "industri\n",
      "have\n",
      "been\n",
      "evolv\n",
      "secur\n",
      "data\n",
      "scienc\n",
      "in\n",
      "order\n",
      "to\n",
      "tackl\n",
      "the\n",
      "challeng\n",
      "of\n",
      "manag\n",
      "and\n",
      "gain\n",
      "insight\n",
      "from\n",
      "huge\n",
      "stream\n",
      "of\n",
      "log\n",
      "data\n",
      ",\n",
      "discov\n",
      "insid\n",
      "threat\n",
      "and\n",
      "prevent\n",
      "fraud\n",
      ".\n",
      "Data\n",
      "scienc\n",
      "compani\n",
      "like\n",
      "Feedzai\n",
      "[\n",
      "15\n",
      "]\n",
      "use\n",
      "a\n",
      "mix\n",
      "of\n",
      "big\n",
      "data\n",
      ",\n",
      "machin\n",
      "learn\n",
      ",\n",
      "and\n",
      "human\n",
      "intellig\n",
      "to\n",
      "identifi\n",
      "fraudul\n",
      "payment\n",
      "transact\n",
      ".\n",
      "Secur\n",
      "data\n",
      "scienc\n",
      "is\n",
      "\"\n",
      "data\n",
      "driven\n",
      ",\n",
      "\"\n",
      "mean\n",
      "that\n",
      "new\n",
      "insight\n",
      "and\n",
      "valu\n",
      "come\n",
      "directli\n",
      "from\n",
      "data\n",
      ".[\n",
      "16\n",
      "]\n",
      "Clinic\n",
      "Data\n",
      "Scienc\n",
      "Data\n",
      "scienc\n",
      "ha\n",
      "alway\n",
      "been\n",
      "promin\n",
      "in\n",
      "the\n",
      "field\n",
      "of\n",
      "clinic\n",
      "trial\n",
      ".\n",
      "Time\n",
      "insight\n",
      "into\n",
      "clinic\n",
      "data\n",
      "provid\n",
      "answer\n",
      "to\n",
      "medic\n",
      "question\n",
      "document\n",
      "the\n",
      "safeti\n",
      "and\n",
      "efficaci\n",
      "of\n",
      "novel\n",
      "and\n",
      "exist\n",
      "therapeut\n",
      "compound\n",
      ".\n",
      "With\n",
      "larg\n",
      "and\n",
      "complex\n",
      "data\n",
      ",\n",
      "clinic\n",
      "data\n",
      "scientist\n",
      "have\n",
      "been\n",
      "produc\n",
      "statist\n",
      "analys\n",
      "of\n",
      "clinic\n",
      "trial\n",
      "for\n",
      "market\n",
      "applic\n",
      "sinc\n",
      "clinic\n",
      "develop\n",
      "ha\n",
      "been\n",
      "requir\n",
      ".\n",
      "In\n",
      "the\n",
      "earli\n",
      "2000\n",
      ",\n",
      "the\n",
      "clinic\n",
      "data\n",
      "scientist\n",
      "evolv\n",
      "from\n",
      "a\n",
      "role\n",
      "of\n",
      "a\n",
      "consult\n",
      "to\n",
      "statistician\n",
      "to\n",
      "a\n",
      "strateg\n",
      "one\n",
      ".\n",
      "Now\n",
      "the\n",
      "clinic\n",
      "data\n",
      "scientist\n",
      "assist\n",
      "in\n",
      "the\n",
      "plan\n",
      ",\n",
      "collect\n",
      ",\n",
      "transform\n",
      ",\n",
      "analysi\n",
      "and\n",
      "report\n",
      "of\n",
      "clinic\n",
      "trial\n",
      "data\n",
      "and\n",
      "commun\n",
      "of\n",
      "their\n",
      "result\n",
      ".\n",
      "These\n",
      "scientist\n",
      "are\n",
      "crucial\n",
      "to\n",
      "the\n",
      "determin\n",
      "of\n",
      "safeti\n",
      "and\n",
      "efficaci\n",
      "of\n",
      "novel\n",
      "therapeut\n",
      "compound\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# examine how weird the tokens get\n",
    "\n",
    "for token in word_bag:\n",
    "    print ps.stem(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
